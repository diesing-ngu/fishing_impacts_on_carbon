---
title: "Dry bulk density - modelling"
output: html_notebook
---

# Install packages

```{r packages, message=FALSE}
rm(list=ls())

if(!require("pacman")) install.packages("pacman"); library(pacman)
p_load(here,
       terra,
       dplyr,
       caret,
       ggplot2,
       sf,
       CAST,
       lwgeom,
       geosphere,
       quantregForest,
       doParallel,
       ModelMetrics,
       forcats)
```


# Preparation

## Which sediment depth interval?

sf: 0 - 2 cm
ss: 2 - 5 cm

```{r depth_interval}
dpt <- "sf"
```


## Get date of latest DBD_sf and OC_sf predictions

```{r get_date}
date1 <- list.files(path = here("dbd_model", "data", "final"), pattern = "DBD_sf_median_")
date1 <- sub(".*?DBD_sf_median_(.*?).tif*", "\\1", date1)
date1 <- as.Date(date1)
date1 <- max(date1)

date2 <- list.files(path = here("toc_model", "data", "final"), pattern = "OC_sf_median_")
date2 <- sub(".*?OC_sf_median_(.*?).tif*", "\\1", date2)
date2 <- as.Date(date2)
date2 <- max(date2)
```


## Load required data

```{r load_data}
DBD <- vect(here("dbd_model", "data", "interim", paste0("DBD_", dpt, ".shp")))
AoI <- read_sf(here("dbd_model", "data", "interim", "AoI.shp"))

predictors <- rast(here("dbd_model", "data", "interim", "predictors.tif"))
if(dpt == "ss"){
  DBDabove <- rast(here("dbd_model", "data", "final", paste0("DBD_sf_median_", date1, ".tif")))
  predictors <- c(predictors, DBDabove)
  names(predictors)[[length(names(predictors))]] <- "DBD_sf"
  rm(DBDabove)
} else {
  OC <- rast(here("toc_model", "data", "final", paste0("OC_sf_median_", date2, ".tif")))
  predictors <- c(predictors, OC)
  names(predictors)[46] <- "OC_sf"
}

names(predictors)
```


## Create regression matrix

```{r update_rm_dbd}
rm_dbd <- as.data.frame(terra::extract(predictors, DBD, bind = TRUE))
rm_dbd <- rm_dbd[-1] #removes first column (ID)
rm_dbd <- na.omit(rm_dbd) #removes rows with NAs
summary(rm_dbd)
```



## Type of response?

Define which property is used as response data.

```{r response_type}
resp_type <- "DBD"
resp_unit <- "g/cm3"
```


# Quantile Regression Forest model

## Distances in environmental space

Distances in environmental (feature) space are computed.

```{r env_space_dist, message=FALSE}
dist_env <- geodist(st_as_sf(DBD), 
                    predictors,
                    type = "feature"
                    )

plot(dist_env)
plot(dist_env) + scale_x_log10()
```


## Distances in geographic space

Distances in geographic space are computed.

```{r geogr_space_dist, message=FALSE}
dist_geogr <- geodist(st_as_sf(DBD), 
                     predictors,
                     type = "geo"
                     )

plot(dist_geogr)
plot(dist_geogr, unit="km") + scale_x_log10()
```


## Creating spatial blocks

Spatial blocks and folds are created. The folds will be used in a spatial k-fold cross validation. The k-fold nearest neighbour distance matching algorithm is used here.

```{r knndm}
DBD <- project(DBD, AoI)
k <- 10 # Number of folds
knndmfolds <- knndm(tpoints = st_as_sf(DBD),
                    modeldomain = AoI,
                    k = k,
                    samplesize = 2000)
```


## Distances in geographic space including CV distances

```{r geogr_space_dist2, message=FALSE}
dist_geogr2 <- geodist(st_as_sf(DBD), 
                       predictors,
                       cvfolds= knndmfolds$indx_test,
                       type = "geo"
                       )

plot(dist_geogr2)
plot(dist_geogr2, unit="km") + scale_x_log10()
```


## Model tuning

A Quantile Regression Forest model is tuned. Predictor variables are selected in a forward feature selection approach and various values of the mtry parameter are tested in a spatial k-fold cross validation.

The maximum number of iterations to be performed can be calculated upfront, based on the number of pre-selected predictors:

```{r max_iter}
factorial(length(names(predictors)))/(factorial(2)*factorial(length(names(predictors))-2)) + sum(c((length(names(predictors))-2):1))
```


### Forward feature selection

The best combination of predictor variables (features) is found in a forward feature selection process.

```{r ffs, message=FALSE, warning=FALSE}
nCores <- detectCores()
cl <- makePSOCKcluster(nCores - 1)
registerDoParallel(cl)

set.seed(42)

model <- ffs(rm_dbd[names(predictors)],
               rm_dbd$DBD,
               metric = "Rsquared",
               method="qrf",
               what = 0.5,
               replace = FALSE,
               importance = TRUE,
               trControl = trainControl(method="CV",
                                        number = k,
                                        savePredictions = "final",
                                        index = knndmfolds$indx_train, 
                                        allowParallel = TRUE),
               verbose = TRUE)

stopCluster(cl)

model

sel_preds <- model$selectedvars
```


### FFS plot

Plot of R2 over the model runs.

```{r ffs_plot}
plot(model)
```


## Validation statistics

The validation results of the optimal RF model.

Note that these are the statistics based on the predicted values of the selected model. These differ from the values from the tuning (above), which are the means of the k predictions based on the folds.

```{r validation_stats}
t <- data.frame(model$pred$pred, model$pred$obs)

validation <- data.frame(mse=numeric(), rmse=numeric(), r2=numeric())
validation[1,1] <- round(sum(t$model.pred.obs - t$model.pred.pred)/nrow(t), 3)
validation[1,2] <- round(rmse(t$model.pred.obs, t$model.pred.pred), 3)
validation[1,3] <- round(cor(t$model.pred.obs, t$model.pred.pred)^2, 3)

colnames(validation) <- c("ME", "RMSE", "r2")
rownames(validation) <- NULL
validation
```


## Validation plot

```{r validation_plot, message=FALSE}
p <-  ggplot(t, aes(x = model.pred.pred, y = model.pred.obs)) +
      geom_abline(intercept = 0, slope = 1, colour = "grey", linewidth = 1.2) +
      geom_smooth(method = "lm") +
      geom_point() +
      scale_fill_continuous(type = "viridis") +
      theme_bw() +
      scale_x_continuous(name = "Predicted value") +
      scale_y_continuous(name = "Observed value") +
      ggtitle(paste0(resp_type, " (", resp_unit, ")"))

p

jpeg(filename = here("dbd_model", "figures", paste0("validation_plot_",resp_type, "_",dpt , ".jpg")), width = 15, height = 10, units = "cm", res = 300)
p
dev.off()
```


## Variable importance

```{r variable_importance_plot, warning=FALSE}
imp <- varImp(model$finalModel, scale = FALSE)
imp$Predictor <- rownames(imp)
rownames(imp) <- NULL
imp <- imp[order(imp[1], decreasing = TRUE), c(2, 1)]
colnames(imp)[2] <- "IncMSE"

impfig <- imp %>%
  mutate(Predictor = fct_reorder(Predictor, IncMSE)) %>%
  ggplot( aes(x=Predictor, y=IncMSE)) +
    geom_bar(stat="identity", fill="#f68060", alpha=.6, width=.4) +
    coord_flip() +
    xlab("") +
    ylab("% increase in MSE") +
    theme_bw()
    
impfig

jpeg(filename = here("dbd_model", "figures", paste0("variable_importance_plot_",resp_type, "_",dpt , ".jpg")), width = 10, height = 10, units = "cm", res = 300)
impfig
dev.off()
```


## Distances in environmental space including CV distances

```{r env_space_dist2, message=FALSE}
dist_env2 <- geodist(st_as_sf(DBD), 
                     predictors,
                     type = "feature",
                     cvfolds= knndmfolds$indx_test,
                     variables = sel_preds
                     )

plot(dist_env2)
plot(dist_env2) + scale_x_log10()
```


## Partial dependence

Partial dependence plots give a graphical depiction of the marginal effect of a variable on the response.

```{r partial_plots}
m2 <- model$finalModel
class(m2) <- "randomForest"

for (i in 1:length(sel_preds)) {
  partialPlot(x = m2, pred.data = rm_dbd, x.var = sel_preds[i], main = "", xlab = sel_preds[i], ylab = paste0(resp_type, " (", resp_unit, ")"))
}

```


# Predict QRF model

## Predict DBD

DBD is predicted. Median values of the QRF distribution are calculated as central values. The 90% prediction interval and the prediction interval ratio are calculated as measures of uncertainty.

```{r predict_dbd}
preds <- raster::stack(predictors[[sel_preds]])
DBD_med <- predict(preds, model$finalModel, what = 0.5)
DBD_p95 <- predict(preds, model$finalModel, what = 0.95)
DBD_p5 <- predict(preds, model$finalModel, what = 0.05)
DBD_pi90 <- DBD_p95 - DBD_p5
DBD_pir <- DBD_pi90 / DBD_med
```


## Area of applicability

```{r aoa}
DBD_trainDI <- trainDI(model = model,
                        variables = sel_preds)
print(DBD_trainDI)

DBD_aoa <- aoa(newdata = predictors, 
                model = model,
                trainDI = DBD_trainDI,
                variables = sel_preds,
)

plot(DBD_aoa)

fr <- freq(DBD_aoa$AOA)
print(paste0("AOA = ", round(100*fr$count[2]/ sum(fr$count),2), "% of pixels"))
```


## Plot results

```{r plot_results}
plot(rast(DBD_med), main = "DBD median")
plot(rast(DBD_pi90), main = "90% prediction interval")
plot(rast(DBD_pir), main = "Prediction interval ratio")
plot(DBD_aoa$DI, main = "Dissimilarity index")
plot(DBD_aoa$AOA, main = "Area of applicability")
```


## Convert AOA from raster to polygon

```{r aoa_poly}
aoa_poly <- as.polygons(DBD_aoa$AOA, dissolve = TRUE)
plot(aoa_poly)

write_sf(st_as_sf(aoa_poly), dsn = here("dbd_model", "data", "final"), layer = paste0("DBD_", dpt, "_AOA_", Sys.Date()), driver = "ESRI Shapefile")
```


## Export results

```{r export_results}
writeRaster(DBD_med, paste0(here("dbd_model", "data", "final"), "/DBD_", dpt, "_median_", Sys.Date(), ".tif"))
writeRaster(DBD_p5, paste0(here("dbd_model", "data", "final"), "/DBD_", dpt, "_P5_", Sys.Date(), ".tif"))
writeRaster(DBD_p95, paste0(here("dbd_model", "data", "final"), "/DBD_", dpt, "_P95_", Sys.Date(), ".tif"))
writeRaster(DBD_pi90, paste0(here("dbd_model", "data", "final"), "/DBD_", dpt, "_PI90_", Sys.Date(), ".tif"))
writeRaster(DBD_pir, paste0(here("dbd_model", "data", "final"), "/DBD_", dpt,  "_PIR_", Sys.Date(), ".tif"))
writeRaster(DBD_aoa$DI, paste0(here("dbd_model", "data", "final"), "/DBD_", dpt, "_DI_", Sys.Date(), ".tif"))
writeRaster(DBD_aoa$AOA, paste0(here("dbd_model", "data", "final"), "/DBD_", dpt, "_AOA_", Sys.Date(), ".tif"))
```


## Output a log file

```{r log}
sink(file = paste0(here("dbd_model", "data", "final", paste0("ModelLog_DBD_", dpt, "_")), Sys.Date(), ".txt"))
model
print("Final Model")
paste0("ME = ", validation[1,1])
paste0("RMSE = ", validation[1,2])
paste0("R2 = ", validation[1,3])
paste0("AOA = ", round(100*fr$count[2]/ sum(fr$count),2), "% of pixels")
sink()
```

